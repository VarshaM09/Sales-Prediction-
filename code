#%%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics
#%% md
# loading the data from csv file to Pandas DataFrame
#%%
big_mart_data = pd.read_csv('Train.csv')
#%%
big_mart_data.head(2)
#%% md
# Six Questions ( preprocessing )
#%%
big_mart_data.shape
#%%
big_mart_data.info()
#%%
big_mart_data.isnull().sum()
#%%
big_mart_data.duplicated().sum()
#%% md
# filling missing values
Item_Weight (filling with its mean)                                              
Outlet_Type ( Filling with its mode)
#%%
big_mart_data['Item_Weight'].fillna(big_mart_data['Item_Weight'].mean(), inplace=True)
#%% md
# filling the missing values in "Outlet_Size" column with Mode
#%%
# mode of "Outlet_Size" column
big_mart_data['Outlet_Size'].mode()
#%%
big_mart_data.columns
#%%
mode_of_outlet_size = big_mart_data.pivot_table(values='Outlet_Size',columns='Outlet_Type',aggfunc=lambda x: x.mode()[0])

#The values parameter specifies that we want to aggregate the Outlet_Size column. 
# The columns parameter specifies that we want to create a separate column for each unique value in the Outlet_Type column.
# The aggfunc parameter specifies the aggregation function to be used. 
# In this case, the lambda x: x.mode()[0] function is used, which finds the mode (most common value)
# of the Outlet_Size column for each group of Outlet_Type and returns the first value of the resulting series.
#%%
mode_of_outlet_size
#%%
miss_values = big_mart_data['Outlet_Size'].isnull()   
#%%
miss_values.value_counts()
#%%
miss_values = big_mart_data['Outlet_Size'].isnull()   
big_mart_data.loc[miss_values, 'Outlet_Size'] = big_mart_data.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_outlet_size[x])
# This line of code is using the Pandas loc method to locate missing values in the Outlet_Size column of the big_mart_data
# dataset. 
#The miss_values variable is assumed to be a Boolean mask that filters out rows where the Outlet_Size column has
#a missing or null value.
#The code then assigns a new value to the Outlet_Size column for these missing values. 
# The new value is determined based on the corresponding value in the Outlet_Type column for each row, 
# using the mode_of_outlet_size variable as a lookup table.
# The apply() method is used to apply a function to each value in the filtered Outlet_Type column.
#In this case, the function being applied is a lambda function that takes each value of x 
#(i.e., each value in the Outlet_Type column) and looks up the corresponding value in the mode_of_outlet_size dictionary.
#%%
# checking for missing values
big_mart_data.isnull().sum()
#%%
big_mart_data.describe()
#%% md
# 2 EDA (Exploratory Data Analysis)
#%%
# Item_Weight distribution
sns.set()
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Weight'])
plt.show()
#%%
# Item Visibility distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Visibility'])
plt.show()
#%%
# Item MRP distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_MRP'])
plt.show()
#%%
# Item_Outlet_Sales distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Outlet_Sales'])
plt.show()
#%%
# Outlet_Establishment_Year column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=big_mart_data)
plt.show()
#%%
# Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=big_mart_data)
plt.show()
#%%
# Item_Type column
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=big_mart_data)
plt.show()
#%%
# Outlet_Size column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=big_mart_data)
plt.show()
#%%
big_mart_data.head()
#%%
# big_mart_data['Item_Fat_Content'].value_counts()
big_mart_data.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)
#%% md
# Label Encoding
#%%
encoder = LabelEncoder()
#%%
big_mart_data['Item_Identifier'] = encoder.fit_transform(big_mart_data['Item_Identifier'])

big_mart_data['Item_Fat_Content'] = encoder.fit_transform(big_mart_data['Item_Fat_Content'])

big_mart_data['Item_Type'] = encoder.fit_transform(big_mart_data['Item_Type'])

big_mart_data['Outlet_Identifier'] = encoder.fit_transform(big_mart_data['Outlet_Identifier'])

big_mart_data['Outlet_Size'] = encoder.fit_transform(big_mart_data['Outlet_Size'])

big_mart_data['Outlet_Location_Type'] = encoder.fit_transform(big_mart_data['Outlet_Location_Type'])

big_mart_data['Outlet_Type'] = encoder.fit_transform(big_mart_data['Outlet_Type'])
#%%
big_mart_data.head()
#%% md
# Splitting Data Into Test and Train Parts
#%%
X = big_mart_data.drop(columns='Item_Outlet_Sales', axis=1)
Y = big_mart_data['Item_Outlet_Sales']
#%%
X.shape
#%%
Y.shape
#%%
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
#%% md
# Machine Learning Model Training
XGBoost Regressor
#%%
regressor = XGBRegressor()
regressor.fit(X_train,Y_train)
y_pred = regressor.predict(X_test)
#%%
metrics.r2_score(Y_test, y_pred)
#%%
big_mart_data.info()
#%%
big_mart_data.sample(4)
#%% md
# Sales Prediction System:
#%%
# 677,19.35,1,0.065891,10,167.0816,2,2007,2,1,1
# 250,6.89,1,0.136428,13,193.9820,8,1997,2,0,1


input = (250,6.89,1,0.136428,13,193.9820,8,1997,2,0,1)
new_input = np.asanyarray(input,dtype=float)
prediciton = regressor.predict(new_input.reshape(1,-1))
print(prediciton)
#%%

#%%
import pickle
pickle.dump(regressor,open('model.pkl','wb'))
#%%

